<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yudum Pa√ßin">
<meta name="dcterms.date" content="2022-10-14">

<title>Yudum Pa√ßin - 1&nbsp; Assigment 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Assigment 1</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Yudum Pa√ßin</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/pjournal/mef06-yudumpacin" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introduction</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignment1.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Assigment 1</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#about-me" id="toc-about-me" class="nav-link active" data-scroll-target="#about-me"><span class="toc-section-number">1.1</span>  <strong>About Me</strong></a></li>
  <li><a href="#advocating-for-automation" id="toc-advocating-for-automation" class="nav-link" data-scroll-target="#advocating-for-automation"><span class="toc-section-number">1.2</span>  <strong>Advocating for Automation</strong></a></li>
  <li><a href="#r-posts" id="toc-r-posts" class="nav-link" data-scroll-target="#r-posts"><span class="toc-section-number">1.3</span>  <strong>3 R Posts</strong></a>
  <ul class="collapse">
  <li><a href="#pca-vs-autoencoders-for-dimensionality-reduction" id="toc-pca-vs-autoencoders-for-dimensionality-reduction" class="nav-link" data-scroll-target="#pca-vs-autoencoders-for-dimensionality-reduction"><span class="toc-section-number">1.3.1</span>  <strong>PCA vs Autoencoders for Dimensionality Reduction</strong></a></li>
  <li><a href="#audio-classification-with-torch" id="toc-audio-classification-with-torch" class="nav-link" data-scroll-target="#audio-classification-with-torch"><span class="toc-section-number">1.3.2</span>  <strong>Audio classification with torch</strong></a></li>
  <li><a href="#update-your-machine-learning-pipeline-with-vetiver-and-quarto" id="toc-update-your-machine-learning-pipeline-with-vetiver-and-quarto" class="nav-link" data-scroll-target="#update-your-machine-learning-pipeline-with-vetiver-and-quarto"><span class="toc-section-number">1.3.3</span>  <strong>Update Your Machine Learning Pipeline With vetiver and Quarto</strong></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Assigment 1</span></h1>
<p class="subtitle lead">About Me and Data Science in R</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yudum Pa√ßin </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 14, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<style>
    body { 
    font-family: Calibri;
    text-align: justify;
    font-size: 11pt;
    }
</style>
<section id="about-me" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="about-me"><span class="header-section-number">1.1</span> <strong>About Me</strong></h2>
<p>Hello everyone! My names is Yudum Pa√ßin. I was born in Bursa, Mudanya, i‚Äôve lived in Mudanya until I went to Ankara for my university education. Now, I have been working as an IT Business Analyst in VakifBank for 6 years. Nowadays, I am about to switch my career path to be a Data Scientist üòÄ. My interest of data science area started in 2019 with the famous Coursera course ‚ÄúMachine Learning‚Äù from Andrew Ng, which i think no longer exists as one course but is converted to a Machine Learning Specialization. But before that, i was in this area before realizing that i am. Let me explain this!</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://fmcalisto.github.io/machine-learning-stanford-coursera/assets/banner.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption"><em>Here is The ‚ÄúMachine Learning Course‚Äù that brought me here</em></figcaption><p></p>
</figure>
</div>
</center>
<p>First of all, I am a Mathematician. I was graduated from <a href="https://math.metu.edu.tr/">Mathematics department of Middle East Technical University</a> in 2012. After graduation, i was sure that my profession will be in the IT sector, but i didn‚Äôt know where to start. To improve my knowledge in software development, I‚Äôve completed master‚Äôs degree in Information Sciences from METU. I‚Äôve also worked as a Research Assistant while i was studying between 2013-2015. During my graduate years i was doing data manipulation, statistical tests, like correlation tests, ANOVA etc., However, this whole process was only a tool for me, i was focused on results not the process. Simply, IBM SPSS was doing it for me. When i first understood the idea behind linear regression with the Machine Learning Course from Coursera i was fascinated with the idea of using Math for this way. As a data science enthusiast and future-data scientist, i want to use machine learning skills to automate the repetitive jobs. I think our human brains deserve better jobs. What i mean by repetitive jobs can be document classification, e-mail replying, classification of incident records from production environments, testing user interfaces etc. Even, reporting to manager can be a machine learning idea for me. To sum up, if there is a work that computers can handle better or equal than humans, then we should find a new way to automate it. Deep learning models are doing great at computer vision and NLP areas, even they are now as successful as human cognitive level in some areas: <a href="https://www.deepmind.com/research/highlighted-research/alphago">Alphago</a>, <a href="https://www.nature.com/articles/s41467-021-21466-z">Ensembled deep learning model outperforms human experts in diagnosing..</a>, <a href="https://www.forbes.com/sites/michaelthomsen/2015/02/19/microsofts-deep-learning-project-outperforms-humans-in-image-recognition/?sh=7f956186740b">Microsoft‚Äôs Deep Learning Project Outperforms Humans In Image Recognition</a></p>
<p>Other than giving humans more respectable jobs and leave others to AI üòÄ, i am planning to work on time series models to predict future and also marketing analytics.</p>
<p>You can reach me via my <strong><a href="https://www.linkedin.com/in/yudum-pacin/">linkedin</a></strong> page.</p>
</section>
<section id="advocating-for-automation" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="advocating-for-automation"><span class="header-section-number">1.2</span> <strong>Advocating for Automation</strong></h2>
<p>This section is from the RStudio talk <strong>‚ÄúAdvocating for Automation: Adapting Current Tools in Environmental Science through R‚Äù</strong> by Hannah Podzorski, GSI Envronmental. Podzorski points out the importance of automation for diverse skilled teams and how it can be applied with R. You can reach the full version of the talk from <a href="https://www.rstudio.com/conference/2022/talks/advocating-for-automation/">rstudio::conf(2022) link</a></p>
<p>The reason why I chose this topic is that I am also trying to find a new way to automate the repetitive tasks and create time for more important ones.</p>
<p>Automation has many pros like</p>
<ul>
<li>Reproducibility</li>
<li>Simplicity</li>
<li>Saving time</li>
<li>Less human interaction which means less errors</li>
</ul>
<p>But, where to start automation? Podzorski suggests to start small. She and other team members first decide to start to automate the process with Microsoft Excel Products using R.</p>
<p><code>{openxlsx}</code> : an R package designed to edit, read and create Excel files.</p>
<p><code>openxlsx::write.xlsx(data,"data.xlsx")</code></p>
<p>The other useful package is <code>{officer}</code>. Officer is used to manipulate word documents and PowerPoints in R. The <a href="https://github.com/hannahpodzorski/advocating-for-automation/blob/main/R/02_officer-plot.R">github page shows</a> how to use it.</p>
<p>The last important package is <code>{rvg}</code>, rvg has a function <strong>dml</strong> which enables the edit ggplot object option before exporting it to a PowerPoint file.</p>
<p>The team of Podzorski later decides to use their automation skills to use ProUCL in a more efficient way. ProUCL is a comprehensive statistical software designed for analyzing enviromental data. The team uses the ProUCL by loading the data and exporting the results for further analysis or reports. In case of loading large data inputs, the software crashes or runs slowly. Because of these reasons, the team decides to automate this process with ‚ÄúMini-Mouse Macro‚Äù. First a function in R, subsets the large data in more manageable chunks, then the mouse macro takes these input files, clicks though the software for getting statistics and finally saves the output file. This can be seen as a small task to automate but when the number of files increases, the time for a human to do this task one by one becomes unmanageable. Also, the team automate the work of copy-paste ProUCL outputs to Excel. As a result of this automation process, the team saves more time for data analysis and creating insights from the results.</p>
</section>
<section id="r-posts" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="r-posts"><span class="header-section-number">1.3</span> <strong>3 R Posts</strong></h2>
<p>In this section, 3 R posts I chose will be summarized and discussed.</p>
<section id="pca-vs-autoencoders-for-dimensionality-reduction" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="pca-vs-autoencoders-for-dimensionality-reduction"><span class="header-section-number">1.3.1</span> <strong>PCA vs Autoencoders for Dimensionality Reduction</strong></h3>
<p><em>You can reach the full version of article from the <a href="https://www.r-bloggers.com/2018/07/pca-vs-autoencoders-for-dimensionality-reduction/">link</a></em></p>
<p>When our data set has too many dimensions, it is a wise desicion to go on with the important ones and leave others. But how to choose important ones? This article compares two methods for dimension reduction, PCA and Autoencoders with R using the Australian Institute of Sport data set.</p>
<p><strong>Principal Components Analysis (PCA)</strong></p>
<p>PCA is a process of reducing the data frame by orthogonality transforming the data into a set of principal components. The first principal component explains the most amount of the variation in the data in a single component, the second component explains the second most amount of the variation, and so on. By choosing the top k principal components that explain say 80-90% of the variation, the other components can be dropped since they do not significantly benefit the model.</p>
<p>To investigate the variation in the data. Plotting the data points in 3 dimensions gives a better indication of the structure of the data. However, there can be still many dimensions which explain some of the variation that are not visualized. To do so they would all need to be plotted in their various combinations. This is a draw back of PCA.</p>
<pre><code># standardise
minmax &lt;- function(x) (x - min(x))/(max(x) - min(x))
x_train &lt;- apply(ais[,1:11], 2, minmax)
# PCA
pca &lt;- prcomp(x_train)</code></pre>
<p><strong>Autoencoder</strong></p>
<p>The autoencoder can be constructed using the keras package. As with any neural network there is a lot of flexibility in how autoencoders can be constructed such as the number of hidden layers and the number of nodes in each. With each hidden layer the network will attempt to find new structures in the data. In general autoencoders are symmetric with the middle layer being the bottleneck. The first half of the autoencoder is considered the encoder and the second half is considered the decoder.</p>
<pre><code># set training data
x_train &lt;- as.matrix(x_train)
# set model
model &lt;- keras_model_sequential()
model %&gt;%
  layer_dense(units = 6, activation = "tanh", input_shape = ncol(x_train)) %&gt;%
  layer_dense(units = 2, activation = "tanh", name = "bottleneck") %&gt;%
  layer_dense(units = 6, activation = "tanh") %&gt;%
  layer_dense(units = ncol(x_train))
# view model layers
summary(model)

# compile model
model %&gt;% compile(
  loss = "mean_squared_error", 
  optimizer = "adam"
)

# fit model
model %&gt;% fit(
  x = x_train, 
  y = x_train, 
  epochs = 2000,
  verbose = 0
)

# evaluate the performance of the model
mse.ae2 &lt;- evaluate(model, x_train, x_train)
mse.ae2
</code></pre>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://media.geeksforgeeks.org/wp-content/uploads/20190618164342/structure1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption"><em>Figure: 1 - Structure of an Autoencoder</em></figcaption><p></p>
</figure>
</div>
<p><em>Image source: https://www.geeksforgeeks.org/ml-auto-encoders/</em></p>
</center>
<p>To summarize, some key differences for consideration between PCA and autoencoders are:</p>
<p>1- There are no guidelines to choose the size of the bottleneck layer in the autoencoder unlike PCA. With PCA, the top k components can be chosen to factor in x% of the variation. Often PCA can be used as a guide to choose k.</p>
<p>2- The autoencoder tends to perform better when k is small.</p>
<p>3- Autoencoders require more computation than PCA..</p>
</section>
<section id="audio-classification-with-torch" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="audio-classification-with-torch"><span class="header-section-number">1.3.2</span> <strong>Audio classification with torch</strong></h3>
<p>In this article classification of audio using R torch is examined. I have tried audio classification with spectograms using Keras tensorflows with Python before, so this topic got my attention.</p>
<p><em>You can reach the full version of article from the <a href="https://blogs.rstudio.com/ai/posts/2022-10-06-audio-classification-torch/">link</a></em></p>
<p>The dataset for this study holds recordings of thirty different one- or two-syllable words, uttered by different speakers. There are about 65,000 audio files. 4 properties are give for each file,</p>
<p>waveform, sample_rate, label_index, and label.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blogs.rstudio.com/ai/posts/2022-10-06-audio-classification-torch/images/audio-bird-waveform.png" class="img-fluid figure-img" style="width:70.0%"></p>
<p></p><figcaption class="figure-caption"><em>Figure 2.1 - The spoken word ‚Äúbird‚Äù: Sound wave</em></figcaption><p></p>
</figure>
</div>
</center>
<p>This representation is actually difference of loudness of voice over time. Author suggests that even the domain experts can conclude that this is not enough for sound classification. To get more meaningful transformation, fourier-transform method is applied for getting a representation of sound in a way that had no information about time at all and have as just as much information as original signal. In R <code>torch_fft_fft</code> function is used, where fft stands for Fast Fourier Transform.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blogs.rstudio.com/ai/posts/2022-10-06-audio-classification-torch/images/audio-bird-dft.png" class="img-fluid figure-img" style="width:70.0%"></p>
<p></p><figcaption class="figure-caption"><em>Figure 2.2 - The spoken word ‚Äúbird‚Äù: Discrete Fourier Transform</em></figcaption><p></p>
</figure>
</div>
</center>
<p>From this alternate representation, original sound wave can be calculated by taking the frequencies present in the signal, weighting them according to their coefficients, and adding them up. But in sound classification, timing information must surely matter, for this reason another represenaiton is necessary.</p>
<p>We can divide the signal into small chunks, and run the Fourier Transform on each of them. This representation is called the spectrogram.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blogs.rstudio.com/ai/posts/2022-10-06-audio-classification-torch/images/audio-spectrogram.png" class="img-fluid figure-img" style="width:70.0%"></p>
<p></p><figcaption class="figure-caption"><em>Figure 2.3 - A spectogram</em></figcaption><p></p>
</figure>
</div>
</center>
<p>The spectrogram is a two-dimensional representation: an image. From now on, we can use convolutional neural networks for image recognition using <code>library(torch)</code>.</p>
<div class="cell">

</div>
</section>
<section id="update-your-machine-learning-pipeline-with-vetiver-and-quarto" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="update-your-machine-learning-pipeline-with-vetiver-and-quarto"><span class="header-section-number">1.3.3</span> <strong>Update Your Machine Learning Pipeline With vetiver and Quarto</strong></h3>
<p>The reason I chose this article is I am curious about how the models are created and deployed in real-life. How is the Machine Learning Pipeline process works?</p>
<p><em>You can reach the full version of article from the <a href="https://www.rstudio.com/blog/update-your-machine-learning-pipeline-with-vetiver-and-quarto/">link</a></em></p>
<p>Machine learing operations (MLOps) are a set of practices for running ML models in production environments. Vertier, an open-source framework for entire morel life cycle, provides R an and Pyhton developers a unified way for working with ML models.</p>
<p>In this article, <a href="https://solutions.rstudio.com/example/bike_predict/">Bike Prediction App</a> is used. The app provides real-time predictions of the number of bikes at stations across the city, Washington D.C.. The end to end machine learning pipeline uses R to modify and import the data, saves it in a <a href="https://pins.rstudio.com/">pin</a>, which is a package publishes data, models, and other R objects. Then the pipeline developes a model and moves the model to a deployable location.</p>
<p>The topic of this article focuses on updating the MLOps using the new vertier framework and Quarto.</p>
<p>Creating An End-to-End Machine Learning Pipeline</p>
<p><strong>1. Create a custom package for pulling data</strong></p>
<p>The data is pulled from <a href="https://www.google.com/search?client=firefox-b-1-d&amp;q=capital+bikshare+api">Capital Bikeshare API</a>. The team developed a R package to reuse the functions pulling the data from API when it is requested.</p>
<p><strong>2. Extract, transform, load process in R</strong></p>
<p>The data from API is raw data, is written on Database. The station info is also written to a pin. This pin will be accessed by the Shiny app so that it can extract the bike station info without connecting to the database.</p>
<p>This step is also called ETL Step 1 - Raw Data Refresh</p>
<p><strong>3. Tidy and join datasets</strong></p>
<p>In this phase raw bike data is preprocessed with <a href="https://www.tidyverse.org/">tidyverse package</a>. Then the bike data is joint with station data. The output data is written to DataBase as a new table.</p>
<p>This step is also called ETL Step 2 - Tidy Data</p>
<p><strong>4. Train and deploy the model</strong></p>
<p>The table resulted from Step 3 is trained with Random Forest Model. The model is saved to RStudio Connect as a pin (using vetiver) and then it is converted into an API endpoint (also using vetiver). Then, the team deployed the API to RStudio Connect.</p>
<p><strong>5. Create a model card</strong></p>
<p>This step includes, evaluation of training and evaluation data by different methods. <a href="https://dl.acm.org/doi/10.1145/3287560.3287596">Vetiver‚Äôs model card</a> template helps document essential facts and considerations of the deployed model.</p>
<p><strong>6. Monitor model metrics</strong></p>
<p>To ensure the consistency of the moddel, the metrics should be monitored. For this prurpose, model performance is documented using vetiver and the metrics are written to a pin on RStudio Connect.</p>
<p><strong>7. Deploy a Shiny app that displays real-time predictions</strong></p>
<p>API endpoint is used to serve predictions to a <a href="https://colorado.rstudio.com/rsc/bike-predict-r-client-app/">Shiny app</a> interactively. Clicking on a station shows us a line graph of the time and predicted number of bikes.</p>
<p><strong>8. Create project dashboard</strong></p>
<p>The team has created a dashboard for sharing the full context of this project.</p>
<p style="font-size: 24pt; color:pink; font-style: italic">
Thanks for reading‚Ä¶
</p>
<div data-align="right">
<p><a href="https://www.linkedin.com/in/yudum-pacin/"> <img alt="linkedin" src="images/linkedin.png" width="30"></a> <a href="https://github.com/yudumpacin"> <img alt="github" src="images/github.png" width="30"></a> <a href="https://twitter.com/pacinoyudum"> <img alt="twitter" src="images/twitter.png" width="30"></a></p>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduction</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><a href="https://mef-bda503.github.io">MEF BDA 503</a></div>
  </div>
</footer>



</body></html>